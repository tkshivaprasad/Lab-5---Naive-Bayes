{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, random, math    \n",
    "import statistics as st \n",
    "def loadcsv(filename):\n",
    "    lines = csv.reader(open(filename, \"r\")) \n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        # converting the attributes from string to floating point numbers\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(dataset, splitRatio):\n",
    "    testSize = int(len(dataset) * splitRatio);\n",
    "    trainSet = list(dataset);\n",
    "    testSet = []\n",
    "    while len(testSet) < testSize:\n",
    "    #randomly pick an instance from training data \n",
    "        index = random.randrange(len(trainSet));\n",
    "        testSet.append(trainSet.pop(index))\n",
    "    return [trainSet, testSet]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary of classes 1 and 0 where the values are the \n",
    "#instacnes belonging to each class\n",
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        x = dataset[i]\n",
    "        if (x[-1] not in separated):\n",
    "                separated[x[-1]] = []\n",
    "        separated[x[-1]].append(x)\n",
    "    return separated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " def compute_mean_std(dataset):   \n",
    "        mean_std = [ (st.mean(attribute), st.stdev(attribute))                       \n",
    "                    for attribute in zip(*dataset)];  #zip(*res) transposes a matrix (2-d array/list)  \n",
    "        del mean_std[-1] # Exclude label  \n",
    "        return mean_std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " def summarizeByClass(dataset): \n",
    "        separated = separateByClass(dataset);   \n",
    "        summary = {} # to store mean and std of +ve and -ve instances   \n",
    "        for classValue, instances in separated.items():                           \n",
    "            #summaries is a dictionary of tuples(mean,std) for each class value      \n",
    "            summary[classValue] = compute_mean_std(instances)    \n",
    "            return summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    " #For continuous attributes p is estimated using Gaussion distribution  \n",
    "def estimateProbability(x, mean, stdev):   \n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))   \n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateClassProbabilities(summaries, testVector): \n",
    "    p = {}           #class and attribute information as mean and sd   \n",
    "    for classValue, classSummaries in summaries.items():   \n",
    "        p[classValue] = 1    \n",
    "        for i in range(len(classSummaries)):    \n",
    "            mean, stdev = classSummaries[i]   \n",
    "            x = testVector[i] #testvector's first attribute                 \n",
    "            #use normal distribution \n",
    "            p[classValue] *= estimateProbability(x, mean, stdev);  \n",
    "            return p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    " def predict(summaries, testVector):   \n",
    "        all_p = calculateClassProbabilities(summaries, testVector)   \n",
    "        bestLabel, bestProb = None, -1   \n",
    "        for lbl, p in all_p.items():#assigns that class which has he highest prob \n",
    "            if bestLabel is None or p > bestProb:  \n",
    "                bestProb = p \n",
    "                bestLabel = lbl   \n",
    "                return bestLabel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    " def perform_classification(summaries, testSet): \n",
    "        predictions = []   \n",
    "        for i in range(len(testSet)):    \n",
    "            result = predict(summaries, testSet[i])  \n",
    "            predictions.append(result)   \n",
    "        return predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing Accuracy\n",
    "def getAccuracy(testSet, predictions): \n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]: \n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pima Indian Diabetes Dataset loaded...\n",
      "Total instances available : 768\n",
      "Total attributes present  : 8\n",
      "First Five instances of dataset:\n",
      "1 : [6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0, 1.0]\n",
      "2 : [1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0, 0.0]\n",
      "3 : [8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0, 1.0]\n",
      "4 : [1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0, 0.0]\n",
      "5 : [0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0, 1.0]\n",
      "\n",
      "Dataset is split into training and testing set.\n",
      "Training examples = 615 \n",
      "Testing examples  = 153\n",
      "\n",
      "Accuracy of the Naive Baysian Classifier is : 66.01307189542483\n"
     ]
    }
   ],
   "source": [
    "dataset = loadcsv('C:\\\\Users\\\\This PC\\\\Desktop\\\\MLLAB\\\\data5.csv');   \n",
    "print('Pima Indian Diabetes Dataset loaded...')   \n",
    "print('Total instances available :',len(dataset))  \n",
    "print('Total attributes present  :',len(dataset[0])-1) \n",
    "print(\"First Five instances of dataset:\")  \n",
    "for i in range(5):       \n",
    "    print(i+1 , ':' , dataset[i]) \n",
    "splitRatio = 0.2          \n",
    "trainingSet, testSet = splitDataset(dataset, splitRatio)   \n",
    "print('\\nDataset is split into training and testing set.') \n",
    "print('Training examples = {0} \\nTesting examples  = {1}'.format(len(trainingSet),len(testSet))) \n",
    "summaries = summarizeByClass(trainingSet); \n",
    "predictions = perform_classification(summaries, testSet)   \n",
    "accuracy = getAccuracy(testSet, predictions) \n",
    "print('\\nAccuracy of the Naive Baysian Classifier is :', accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
